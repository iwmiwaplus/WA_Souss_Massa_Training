{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2074066",
   "metadata": {},
   "source": [
    "# 5. Calculate Sheet fluxes Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9600cc6",
   "metadata": {},
   "source": [
    "# 5.1 Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "#import WAPORWA modules\n",
    "os.chdir(r'C:\\WA_Souss_Massa_Training\\WAPOR\\modules') #change to modules path\n",
    "import WA\n",
    "from WA.pickle_basin import pickle_in,pickle_out  \n",
    "from WA.model_SMBalance import open_nc\n",
    "from WA import GIS_functions as gis\n",
    "from dask.distributed import Client\n",
    "\n",
    "#Read pickle\n",
    "Main_dir=r\"C:\\WA_Souss_Massa_Training\\WAPOR\\Souss_Massa\\Main\"\n",
    "pickle=glob.glob(os.path.join(Main_dir,'*.pickle'))[-1] \n",
    "BASIN=pickle_in(pickle)  \n",
    "\n",
    "#Customize dask performance\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8da7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time='A-{0}'.format(BASIN['end_month'])\n",
    "for key in ['p','et','etincr','etrain']:\n",
    "    nc=BASIN['main_data']['monthly'][key]\n",
    "    var,name=open_nc(nc)\n",
    "    var_y=var.resample(time=time).sum(dim='time',skipna=False)\n",
    "    outfolder=os.path.join(BASIN['Dir'],'data','nc')  \n",
    "    attrs={\"units\":\"mm/year\", \"source\": \"Hydrolological year \", \"quantity\":name}\n",
    "    var_y.assign_attrs(attrs)\n",
    "    var_y.name = name\n",
    "    var_y_dts=var_y.chunk({\"latitude\":-1,\"longitude\":-1}).to_dataset()\n",
    "    nc_fn=\"{0}_hyearly.nc\".format(key)\n",
    "    nc_path=os.path.join(outfolder,nc_fn)\n",
    "    var_y_dts.to_netcdf(nc_path,encoding={name:{'zlib':True}})\n",
    "    BASIN['main_data']['yearly'][key]=nc_path\n",
    "pickle_out(BASIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca856d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Create Area mask\n",
    "# get template from LU map\n",
    "template=glob.glob(os.path.join(BASIN['input_data']['yearly']['lu'][0],\"*.tif\"))[0]\n",
    "driver, NDV, xsize, ysize, GeoT, Projection = gis.GetGeoInfo(template)\n",
    "# calculate area per pixel\n",
    "area_map=gis.MapPixelAreakm(template)\n",
    "# save area map as tif\n",
    "\n",
    "Dir_stat = os.path.join(BASIN['Dir'],'data','stat')\n",
    "if not os.path.exists(Dir_stat):\n",
    "    os.makedirs(Dir_stat)\n",
    "\n",
    "BASIN['input_data']['stat']['area']=os.path.join(Dir_stat,'Area_km.tif')    \n",
    "gis.CreateGeoTiff(BASIN['input_data']['stat']['area'],area_map,driver, NDV, xsize, ysize, GeoT, Projection)\n",
    "\n",
    "# create area mask\n",
    "shape=BASIN['geo_data']['basin'] #Shapefile of the area of interest\n",
    "area=BASIN['input_data']['stat']['area']\n",
    "BASIN['main_data']['stat']['area']=os.path.join(BASIN['Dir'],'data','stat','Basin_Area_km.tif')\n",
    "gis.Clip_shapefile(area,shape,BASIN['main_data']['stat']['area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c7cfb",
   "metadata": {},
   "source": [
    "# 5.2 Calculate Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cffb15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select area of interest\n",
    "area_fh=BASIN['main_data']['stat']['area'] # The whole Basin area\n",
    "# area_fh=Basin['main_data']['subbasin']['Zarqa'] #or sub-basin area\n",
    "area=gis.OpenAsArray(area_fh,nan_values=True)\n",
    "\n",
    "### Calculate total P, ET, ETincr, ETrain\n",
    "ts_all=[] #all timeseries\n",
    "for key in ['p','et','etrain','etincr']:\n",
    "    nc=BASIN['main_data']['yearly'][key]\n",
    "    var,name=open_nc(nc)\n",
    "    Volume=var*area\n",
    "    attrs=var.attrs\n",
    "    attrs['units']='TCM/year'\n",
    "    Volume.assign_attrs(attrs)\n",
    "    ts=Volume.sum(dim=['latitude','longitude']).to_dataframe()\n",
    "    ts.index=[y.year for y in ts.index]\n",
    "    ts_all.append(ts)\n",
    "    \n",
    "### Calculate ET consumptions by Land Use Categories\n",
    "LU,_=open_nc(BASIN['main_data']['yearly']['lu'])\n",
    "ETg,_=open_nc(BASIN['main_data']['yearly']['etrain'])\n",
    "ETb,_=open_nc(BASIN['main_data']['yearly']['etincr'])\n",
    "\n",
    "\n",
    "### Different year date to year \n",
    "LU=LU.groupby('time.year').first(skipna=False)\n",
    "ETb=area*ETb.groupby('time.year').first(skipna=False)\n",
    "ETg=area*ETg.groupby('time.year').first(skipna=False)\n",
    "### average per LU\n",
    "from WA.average_by_LU import Total_perLU\n",
    "ts_ETb=Total_perLU(ETb,LU)\n",
    "ts_ETg=Total_perLU(ETg,LU)\n",
    "\n",
    "ts_all.append(ts_ETb)\n",
    "ts_all.append(ts_ETg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc4125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read yearly dS from GRACE\n",
    "df_dS_y=pd.read_csv(BASIN['input_ts']['dS_yearly'][0],sep=';',index_col=0)\n",
    "Area_skm=np.nansum(area)\n",
    "df_grace_ds=df_dS_y*Area_skm\n",
    "df_grace_ds.index=[int(y[0:4]) for y in df_grace_ds.index]\n",
    "df_grace_ds=df_grace_ds.rename(columns={'TWS Change [mm/year]':'dS_GRACE'})\n",
    "ts_all.append(df_grace_ds)\n",
    "\n",
    "### Read monthly Qout\n",
    "for key in ['Qoutlet','Qswout','Qgwout']:\n",
    "    if BASIN['input_ts'][key] is None:\n",
    "        Q=ts_all[0]*0\n",
    "        Q.columns=[key]\n",
    "        ts_all.append(Q)\n",
    "    else:        \n",
    "        Q_m=pd.read_csv(BASIN['input_ts'][key],sep=';',index_col=0,skiprows=0)\n",
    "        Q_m.index=[datetime.datetime.strptime(y,'%d/%m/%Y %H:%M') for y in Q_m.index]\n",
    "        Q_m=Q_m.replace(-9999,np.nan)\n",
    "        Q_y=Q_m.resample('A-{0}'.format(BASIN['end_month'])).sum() #mean()\n",
    "        Q_y.index=[y.year for y in Q_y.index]\n",
    "        ##\n",
    "        df_Q_y=Q_y.where(Q_y.days>=365) ##remove years with missing data\n",
    "        df_Q_y=df_Q_y['km3/month']*1000000 ##convert to TCM=km2*mm\n",
    "        df_Q_y=df_Q_y.dropna()\n",
    "        df_Q_y.name=key\n",
    "        Q=df_Q_y.to_frame()\n",
    "        ts_all.append(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8608dbe",
   "metadata": {},
   "source": [
    "# 5.3 Generate output table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225eeab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ts_all)):\n",
    "    if i ==0:\n",
    "        df=ts_all[i]        \n",
    "    else:\n",
    "        df=pd.merge(df,ts_all[i],left_index=True,right_index=True,how='inner')\n",
    "        \n",
    "df['dS_WB']=df['Precipitation']-df['Actual Evapotranspiration']-df['Qoutlet']-df['Qswout']-df['Qgwout']\n",
    "df['dS_Error']=df['dS_GRACE']-df['dS_WB']\n",
    "\n",
    "OUT_CSV=os.path.join(BASIN['Dir'],'df_all.csv')\n",
    "df.to_csv(OUT_CSV,sep=';')\n",
    "BASIN['main_data']['df_all']=OUT_CSV\n",
    "pickle_out(BASIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b06846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sheet1 csv template\n",
    "WORKING_DIR=WA.__path__[0]\n",
    "csv_template=os.path.join(WORKING_DIR,'csv','Sample_sheet1.csv')\n",
    "\n",
    "convert_unit=1000000 #from TCM to BCM\n",
    "# convert_unit=1000 #from TCM to MCM\n",
    "\n",
    "df=pd.read_csv(BASIN['main_data']['df_all'],sep=';',index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efd3eb5",
   "metadata": {},
   "source": [
    "# 5.4 Generate yearly csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df/convert_unit\n",
    "csv_folder=os.path.join(BASIN['Dir'],'data','csv')\n",
    "if not os.path.exists(csv_folder):\n",
    "    os.makedirs(csv_folder)\n",
    "\n",
    "df_template=pd.read_csv(csv_template,sep=\";\")\n",
    "csv_fhs=[]\n",
    "for year in df.index:\n",
    "    df_year=df_template.copy()\n",
    "    df_year['VALUE']=0.0\n",
    "    df_year.loc[0,'VALUE']=df.loc[year,'Precipitation']\n",
    "#    if df.loc[year,'dS']>0:\n",
    "#        df_year.loc[11,'VALUE']=df.loc[year,'dS_WB']\n",
    "#    else:\n",
    "#        df_year.loc[10,'VALUE']=abs(df.loc[year,'dS_WB'])\n",
    "    df_year.loc[10,'VALUE']=-df.loc[year,'dS_WB']\n",
    "    df_year.loc[12,'VALUE']=df.loc[year,'Rainfall_ET_M-Protected Landuse']\n",
    "    df_year.loc[13,'VALUE']=df.loc[year,'Rainfall_ET_M-Utilized Landuse']\n",
    "    df_year.loc[14,'VALUE']=df.loc[year,'Rainfall_ET_M-Modified Landuse']\n",
    "    df_year.loc[15,'VALUE']=df.loc[year,'Rainfall_ET_M-Managed Water Use']\n",
    "    df_year.loc[16,'VALUE']=df.loc[year,'Incremental_ET_M-Protected Landuse']\n",
    "    df_year.loc[17,'VALUE']=df.loc[year,'Incremental_ET_M-Utilized Landuse']\n",
    "    df_year.loc[18,'VALUE']=df.loc[year,'Incremental_ET_M-Modified Landuse']\n",
    "    df_year.loc[19,'VALUE']=df.loc[year,'Incremental_ET_M-Managed Water Use']\n",
    "    df_year.loc[20,'VALUE']=df.loc[year,'Incremental_ET_M-Managed Water Use']\n",
    "    df_year.loc[21,'VALUE']=df.loc[year,'Incremental_ET_M']-df.loc[year,'Incremental_ET_M-Managed Water Use']\n",
    "    df_year.loc[26,'VALUE']=df.loc[year,'Qswout']\n",
    "    df_year.loc[22,'VALUE']=df.loc[year,'Qoutlet']\n",
    "    outcsv=os.path.join(csv_folder,'Sheet1_{0}.csv'.format(int(year)))\n",
    "    df_year.to_csv(outcsv,sep=\";\",index=False)\n",
    "    csv_fhs.append(outcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ec563b",
   "metadata": {},
   "source": [
    "# 5.5 Compute mean csv file (from all the years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df.mean()  \n",
    "df_mean_csv=df_template.copy()\n",
    "df_mean_csv['VALUE']=0.0\n",
    "df_mean_csv.loc[0,'VALUE']=df_mean.loc['Precipitation']\n",
    "df_mean_csv.loc[10,'VALUE']=-df_mean.loc['dS_WB']\n",
    "df_mean_csv.loc[12,'VALUE']=df_mean.loc['Rainfall_ET_M-Protected Landuse']\n",
    "df_mean_csv.loc[13,'VALUE']=df_mean.loc['Rainfall_ET_M-Utilized Landuse']\n",
    "df_mean_csv.loc[14,'VALUE']=df_mean.loc['Rainfall_ET_M-Modified Landuse']\n",
    "df_mean_csv.loc[15,'VALUE']=df_mean.loc['Rainfall_ET_M-Managed Water Use']\n",
    "df_mean_csv.loc[16,'VALUE']=df_mean.loc['Incremental_ET_M-Protected Landuse']\n",
    "df_mean_csv.loc[17,'VALUE']=df_mean.loc['Incremental_ET_M-Utilized Landuse']\n",
    "df_mean_csv.loc[18,'VALUE']=df_mean.loc['Incremental_ET_M-Modified Landuse']\n",
    "df_mean_csv.loc[19,'VALUE']=df_mean.loc['Incremental_ET_M-Managed Water Use']\n",
    "df_mean_csv.loc[20,'VALUE']=df_mean.loc['Incremental_ET_M-Managed Water Use']\n",
    "df_mean_csv.loc[21,'VALUE']=df_mean.loc['Incremental_ET_M']-df.loc[year,'Incremental_ET_M-Managed Water Use']\n",
    "df_mean_csv.loc[26,'VALUE']=df_mean.loc['Qswout']\n",
    "df_mean_csv.loc[22,'VALUE']=df_mean.loc['Qoutlet']\n",
    "outcsv=os.path.join(csv_folder,'Sheet_{}-{}.csv'.format(min(df.index),max(df.index)))\n",
    "df_mean_csv.to_csv(outcsv,sep=\";\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
